---
layout: post
title: A Journey to the Tip of Neural Networks
date: 2018-04-29 13:50:00 +0900
categories:
  - Machine Learning
tags:
  - Classification
  - Logistic Regression
  - Neural Networks
references:
  - The Element of Statistical Learning, 2E, Hastie et al.
  - https://github.com/dgkim5360/the-elements-of-statistical-learning-notebooks#(shameless plug)
---

## tl;dr
The below Jupyter notebook starts with the most basic tools of machine learning: Linear regression and logistic regression. Then we can go beyond the linear prediction via the scheme of basis expansion using the same linear methods. The basis expansion model and the neural network model seem similar but also different.

In the analogy of parenting style, the basis expansion is the helicopter mom, while the neural network mom is hand-off parenting style. The conclusion is that the basis expansion model has clear interpretation, while the neural network model has black-box characteristic but flexibility.

## Notebook for more
Below is my jupyter notebook (hosted on [kyso.io](//kyso.io)) containing the whole story. It is originally uploaded on [the Github repository](//github.com/dgkim5360/the-elements-of-statistical-learning-notebooks/blob/master/articles/a-journey-to-the-tip-of-neural-networks.ipynb).

<iframe src="https://kyso.io/Don/a-journey-to-the-tip-of-neural-networks/embed?code=shown" width="100%" height="28000px" frameBorder="0"></iframe>
